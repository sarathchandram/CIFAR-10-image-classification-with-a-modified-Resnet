{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a39188-ed05-4fb1-9b17-e06e083e8829",
   "metadata": {},
   "source": [
    "This is the best variation of model 1 with SGD optimizer with momentum=0.9, weight decay = 1e-4, learning rate=0.05. This gave a better results over the first run with learning rate = 0.1. It is a residual network consisting of 4 layers with 1,2,2,3 residual blocks. This run has provided us with the direction for tuning parameters of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7d0172-6e23-4bef-96aa-a1ef6289ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fb88d0a-2202-43a8-92e8-735da2b63660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.linearh = nn.Linear(256*block.expansion, 512)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # out = self.layer5(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.linearh(out))\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18_reduced_param():\n",
    "    return ResNet(BasicBlock, [1, 2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32f8c818-313e-4764-837b-e60181e8d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093866\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18_reduced_param()\n",
    "sum = 0\n",
    "for p in model.parameters():\n",
    "    sum += p.numel()\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09911b5c-db00-4dd5-ac76-eaadb943ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d6ea8c-b586-41c2-88bf-567cc97f95e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c134d38-16a3-4a11-8463-e7495e8bcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18_reduced_param()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bb56658-df97-4346-8018-07d4e965491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0efdc4a8-eb0a-49c2-96b7-c8e146fa45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('Train Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print('Test Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63921dc7-2e1d-4b48-b28b-027750c3f4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Loss: 1.506 | Acc: 44.166% (22083/50000)\n",
      "Test Loss: 1.512 | Acc: 49.450% (4945/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss: 1.017 | Acc: 63.692% (31846/50000)\n",
      "Test Loss: 1.018 | Acc: 65.410% (6541/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss: 0.805 | Acc: 71.718% (35859/50000)\n",
      "Test Loss: 0.818 | Acc: 72.320% (7232/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss: 0.692 | Acc: 76.014% (38007/50000)\n",
      "Test Loss: 0.705 | Acc: 76.260% (7626/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss: 0.612 | Acc: 78.652% (39326/50000)\n",
      "Test Loss: 0.632 | Acc: 78.560% (7856/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss: 0.552 | Acc: 80.820% (40410/50000)\n",
      "Test Loss: 0.587 | Acc: 79.270% (7927/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss: 0.504 | Acc: 82.554% (41277/50000)\n",
      "Test Loss: 0.534 | Acc: 82.030% (8203/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss: 0.470 | Acc: 83.664% (41832/50000)\n",
      "Test Loss: 0.533 | Acc: 82.050% (8205/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss: 0.438 | Acc: 84.860% (42430/50000)\n",
      "Test Loss: 0.449 | Acc: 84.430% (8443/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss: 0.406 | Acc: 85.960% (42980/50000)\n",
      "Test Loss: 0.458 | Acc: 84.240% (8424/10000)\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss: 0.384 | Acc: 86.758% (43379/50000)\n",
      "Test Loss: 0.432 | Acc: 84.920% (8492/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 11\n",
      "Train Loss: 0.364 | Acc: 87.366% (43683/50000)\n",
      "Test Loss: 0.449 | Acc: 84.640% (8464/10000)\n",
      "\n",
      "Epoch: 12\n",
      "Train Loss: 0.342 | Acc: 88.074% (44037/50000)\n",
      "Test Loss: 0.479 | Acc: 84.260% (8426/10000)\n",
      "\n",
      "Epoch: 13\n",
      "Train Loss: 0.326 | Acc: 88.718% (44359/50000)\n",
      "Test Loss: 0.406 | Acc: 86.360% (8636/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      "Train Loss: 0.304 | Acc: 89.516% (44758/50000)\n",
      "Test Loss: 0.408 | Acc: 86.260% (8626/10000)\n",
      "\n",
      "Epoch: 15\n",
      "Train Loss: 0.292 | Acc: 89.762% (44881/50000)\n",
      "Test Loss: 0.446 | Acc: 85.350% (8535/10000)\n",
      "\n",
      "Epoch: 16\n",
      "Train Loss: 0.280 | Acc: 90.232% (45116/50000)\n",
      "Test Loss: 0.458 | Acc: 85.400% (8540/10000)\n",
      "\n",
      "Epoch: 17\n",
      "Train Loss: 0.266 | Acc: 90.754% (45377/50000)\n",
      "Test Loss: 0.386 | Acc: 87.620% (8762/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 18\n",
      "Train Loss: 0.253 | Acc: 91.036% (45518/50000)\n",
      "Test Loss: 0.369 | Acc: 87.700% (8770/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      "Train Loss: 0.239 | Acc: 91.520% (45760/50000)\n",
      "Test Loss: 0.369 | Acc: 87.830% (8783/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      "Train Loss: 0.229 | Acc: 92.028% (46014/50000)\n",
      "Test Loss: 0.402 | Acc: 87.590% (8759/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Train Loss: 0.218 | Acc: 92.200% (46100/50000)\n",
      "Test Loss: 0.380 | Acc: 87.590% (8759/10000)\n",
      "\n",
      "Epoch: 22\n",
      "Train Loss: 0.210 | Acc: 92.674% (46337/50000)\n",
      "Test Loss: 0.373 | Acc: 88.140% (8814/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 23\n",
      "Train Loss: 0.203 | Acc: 92.772% (46386/50000)\n",
      "Test Loss: 0.359 | Acc: 88.190% (8819/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 24\n",
      "Train Loss: 0.198 | Acc: 93.058% (46529/50000)\n",
      "Test Loss: 0.366 | Acc: 88.370% (8837/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 25\n",
      "Train Loss: 0.188 | Acc: 93.378% (46689/50000)\n",
      "Test Loss: 0.354 | Acc: 88.920% (8892/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 26\n",
      "Train Loss: 0.180 | Acc: 93.714% (46857/50000)\n",
      "Test Loss: 0.339 | Acc: 89.100% (8910/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 27\n",
      "Train Loss: 0.172 | Acc: 93.884% (46942/50000)\n",
      "Test Loss: 0.351 | Acc: 89.440% (8944/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 28\n",
      "Train Loss: 0.164 | Acc: 94.156% (47078/50000)\n",
      "Test Loss: 0.384 | Acc: 88.600% (8860/10000)\n",
      "\n",
      "Epoch: 29\n",
      "Train Loss: 0.159 | Acc: 94.434% (47217/50000)\n",
      "Test Loss: 0.348 | Acc: 89.440% (8944/10000)\n",
      "\n",
      "Epoch: 30\n",
      "Train Loss: 0.154 | Acc: 94.516% (47258/50000)\n",
      "Test Loss: 0.338 | Acc: 89.560% (8956/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 31\n",
      "Train Loss: 0.145 | Acc: 94.800% (47400/50000)\n",
      "Test Loss: 0.376 | Acc: 89.020% (8902/10000)\n",
      "\n",
      "Epoch: 32\n",
      "Train Loss: 0.142 | Acc: 94.990% (47495/50000)\n",
      "Test Loss: 0.330 | Acc: 90.010% (9001/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 33\n",
      "Train Loss: 0.131 | Acc: 95.442% (47721/50000)\n",
      "Test Loss: 0.391 | Acc: 88.950% (8895/10000)\n",
      "\n",
      "Epoch: 34\n",
      "Train Loss: 0.129 | Acc: 95.344% (47672/50000)\n",
      "Test Loss: 0.355 | Acc: 89.880% (8988/10000)\n",
      "\n",
      "Epoch: 35\n",
      "Train Loss: 0.123 | Acc: 95.638% (47819/50000)\n",
      "Test Loss: 0.375 | Acc: 89.180% (8918/10000)\n",
      "\n",
      "Epoch: 36\n",
      "Train Loss: 0.118 | Acc: 95.774% (47887/50000)\n",
      "Test Loss: 0.362 | Acc: 89.570% (8957/10000)\n",
      "\n",
      "Epoch: 37\n",
      "Train Loss: 0.116 | Acc: 95.888% (47944/50000)\n",
      "Test Loss: 0.404 | Acc: 88.850% (8885/10000)\n",
      "\n",
      "Epoch: 38\n",
      "Train Loss: 0.114 | Acc: 95.994% (47997/50000)\n",
      "Test Loss: 0.341 | Acc: 90.100% (9010/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 39\n",
      "Train Loss: 0.102 | Acc: 96.418% (48209/50000)\n",
      "Test Loss: 0.387 | Acc: 89.630% (8963/10000)\n",
      "\n",
      "Epoch: 40\n",
      "Train Loss: 0.101 | Acc: 96.376% (48188/50000)\n",
      "Test Loss: 0.368 | Acc: 90.030% (9003/10000)\n",
      "\n",
      "Epoch: 41\n",
      "Train Loss: 0.101 | Acc: 96.342% (48171/50000)\n",
      "Test Loss: 0.394 | Acc: 89.760% (8976/10000)\n",
      "\n",
      "Epoch: 42\n",
      "Train Loss: 0.095 | Acc: 96.704% (48352/50000)\n",
      "Test Loss: 0.367 | Acc: 90.150% (9015/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 43\n",
      "Train Loss: 0.089 | Acc: 96.834% (48417/50000)\n",
      "Test Loss: 0.371 | Acc: 90.230% (9023/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 44\n",
      "Train Loss: 0.087 | Acc: 96.822% (48411/50000)\n",
      "Test Loss: 0.387 | Acc: 90.080% (9008/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Train Loss: 0.085 | Acc: 96.946% (48473/50000)\n",
      "Test Loss: 0.374 | Acc: 90.050% (9005/10000)\n",
      "\n",
      "Epoch: 46\n",
      "Train Loss: 0.080 | Acc: 97.252% (48626/50000)\n",
      "Test Loss: 0.371 | Acc: 90.230% (9023/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Train Loss: 0.078 | Acc: 97.216% (48608/50000)\n",
      "Test Loss: 0.376 | Acc: 90.180% (9018/10000)\n",
      "\n",
      "Epoch: 48\n",
      "Train Loss: 0.076 | Acc: 97.314% (48657/50000)\n",
      "Test Loss: 0.398 | Acc: 89.970% (8997/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Train Loss: 0.075 | Acc: 97.300% (48650/50000)\n",
      "Test Loss: 0.403 | Acc: 90.340% (9034/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 50\n",
      "Train Loss: 0.071 | Acc: 97.466% (48733/50000)\n",
      "Test Loss: 0.381 | Acc: 90.400% (9040/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 51\n",
      "Train Loss: 0.068 | Acc: 97.492% (48746/50000)\n",
      "Test Loss: 0.410 | Acc: 89.900% (8990/10000)\n",
      "\n",
      "Epoch: 52\n",
      "Train Loss: 0.069 | Acc: 97.488% (48744/50000)\n",
      "Test Loss: 0.399 | Acc: 90.010% (9001/10000)\n",
      "\n",
      "Epoch: 53\n",
      "Train Loss: 0.063 | Acc: 97.762% (48881/50000)\n",
      "Test Loss: 0.401 | Acc: 90.280% (9028/10000)\n",
      "\n",
      "Epoch: 54\n",
      "Train Loss: 0.058 | Acc: 97.946% (48973/50000)\n",
      "Test Loss: 0.399 | Acc: 90.430% (9043/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 55\n",
      "Train Loss: 0.058 | Acc: 97.930% (48965/50000)\n",
      "Test Loss: 0.414 | Acc: 90.090% (9009/10000)\n",
      "\n",
      "Epoch: 56\n",
      "Train Loss: 0.060 | Acc: 97.860% (48930/50000)\n",
      "Test Loss: 0.419 | Acc: 90.120% (9012/10000)\n",
      "\n",
      "Epoch: 57\n",
      "Train Loss: 0.056 | Acc: 98.012% (49006/50000)\n",
      "Test Loss: 0.398 | Acc: 90.640% (9064/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 58\n",
      "Train Loss: 0.053 | Acc: 98.100% (49050/50000)\n",
      "Test Loss: 0.432 | Acc: 89.900% (8990/10000)\n",
      "\n",
      "Epoch: 59\n",
      "Train Loss: 0.050 | Acc: 98.200% (49100/50000)\n",
      "Test Loss: 0.406 | Acc: 90.640% (9064/10000)\n",
      "\n",
      "Epoch: 60\n",
      "Train Loss: 0.050 | Acc: 98.258% (49129/50000)\n",
      "Test Loss: 0.410 | Acc: 90.320% (9032/10000)\n",
      "\n",
      "Epoch: 61\n",
      "Train Loss: 0.046 | Acc: 98.368% (49184/50000)\n",
      "Test Loss: 0.411 | Acc: 90.640% (9064/10000)\n",
      "\n",
      "Epoch: 62\n",
      "Train Loss: 0.047 | Acc: 98.382% (49191/50000)\n",
      "Test Loss: 0.446 | Acc: 90.050% (9005/10000)\n",
      "\n",
      "Epoch: 63\n",
      "Train Loss: 0.046 | Acc: 98.346% (49173/50000)\n",
      "Test Loss: 0.445 | Acc: 90.210% (9021/10000)\n",
      "\n",
      "Epoch: 64\n",
      "Train Loss: 0.046 | Acc: 98.442% (49221/50000)\n",
      "Test Loss: 0.396 | Acc: 90.660% (9066/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 65\n",
      "Train Loss: 0.041 | Acc: 98.582% (49291/50000)\n",
      "Test Loss: 0.397 | Acc: 90.720% (9072/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 66\n",
      "Train Loss: 0.038 | Acc: 98.696% (49348/50000)\n",
      "Test Loss: 0.421 | Acc: 90.780% (9078/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 67\n",
      "Train Loss: 0.041 | Acc: 98.584% (49292/50000)\n",
      "Test Loss: 0.407 | Acc: 91.150% (9115/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 68\n",
      "Train Loss: 0.040 | Acc: 98.588% (49294/50000)\n",
      "Test Loss: 0.428 | Acc: 90.870% (9087/10000)\n",
      "\n",
      "Epoch: 69\n",
      "Train Loss: 0.039 | Acc: 98.622% (49311/50000)\n",
      "Test Loss: 0.408 | Acc: 90.960% (9096/10000)\n",
      "\n",
      "Epoch: 70\n",
      "Train Loss: 0.033 | Acc: 98.832% (49416/50000)\n",
      "Test Loss: 0.439 | Acc: 90.820% (9082/10000)\n",
      "\n",
      "Epoch: 71\n",
      "Train Loss: 0.037 | Acc: 98.724% (49362/50000)\n",
      "Test Loss: 0.414 | Acc: 91.060% (9106/10000)\n",
      "\n",
      "Epoch: 72\n",
      "Train Loss: 0.031 | Acc: 98.898% (49449/50000)\n",
      "Test Loss: 0.423 | Acc: 90.950% (9095/10000)\n",
      "\n",
      "Epoch: 73\n",
      "Train Loss: 0.031 | Acc: 98.912% (49456/50000)\n",
      "Test Loss: 0.431 | Acc: 90.920% (9092/10000)\n",
      "\n",
      "Epoch: 74\n",
      "Train Loss: 0.032 | Acc: 98.890% (49445/50000)\n",
      "Test Loss: 0.419 | Acc: 91.090% (9109/10000)\n",
      "\n",
      "Epoch: 75\n",
      "Train Loss: 0.028 | Acc: 99.060% (49530/50000)\n",
      "Test Loss: 0.459 | Acc: 90.700% (9070/10000)\n",
      "\n",
      "Epoch: 76\n",
      "Train Loss: 0.028 | Acc: 98.984% (49492/50000)\n",
      "Test Loss: 0.433 | Acc: 91.270% (9127/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 77\n",
      "Train Loss: 0.029 | Acc: 98.940% (49470/50000)\n",
      "Test Loss: 0.446 | Acc: 90.750% (9075/10000)\n",
      "\n",
      "Epoch: 78\n",
      "Train Loss: 0.029 | Acc: 99.066% (49533/50000)\n",
      "Test Loss: 0.442 | Acc: 91.330% (9133/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 79\n",
      "Train Loss: 0.023 | Acc: 99.202% (49601/50000)\n",
      "Test Loss: 0.439 | Acc: 91.130% (9113/10000)\n",
      "\n",
      "Epoch: 80\n",
      "Train Loss: 0.023 | Acc: 99.188% (49594/50000)\n",
      "Test Loss: 0.447 | Acc: 91.110% (9111/10000)\n",
      "\n",
      "Epoch: 81\n",
      "Train Loss: 0.022 | Acc: 99.206% (49603/50000)\n",
      "Test Loss: 0.460 | Acc: 91.110% (9111/10000)\n",
      "\n",
      "Epoch: 82\n",
      "Train Loss: 0.023 | Acc: 99.224% (49612/50000)\n",
      "Test Loss: 0.470 | Acc: 91.110% (9111/10000)\n",
      "\n",
      "Epoch: 83\n",
      "Train Loss: 0.022 | Acc: 99.252% (49626/50000)\n",
      "Test Loss: 0.450 | Acc: 91.420% (9142/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 84\n",
      "Train Loss: 0.022 | Acc: 99.238% (49619/50000)\n",
      "Test Loss: 0.449 | Acc: 91.160% (9116/10000)\n",
      "\n",
      "Epoch: 85\n",
      "Train Loss: 0.021 | Acc: 99.242% (49621/50000)\n",
      "Test Loss: 0.465 | Acc: 91.250% (9125/10000)\n",
      "\n",
      "Epoch: 86\n",
      "Train Loss: 0.020 | Acc: 99.320% (49660/50000)\n",
      "Test Loss: 0.456 | Acc: 91.480% (9148/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 87\n",
      "Train Loss: 0.020 | Acc: 99.276% (49638/50000)\n",
      "Test Loss: 0.469 | Acc: 91.080% (9108/10000)\n",
      "\n",
      "Epoch: 88\n",
      "Train Loss: 0.016 | Acc: 99.454% (49727/50000)\n",
      "Test Loss: 0.486 | Acc: 91.290% (9129/10000)\n",
      "\n",
      "Epoch: 89\n",
      "Train Loss: 0.020 | Acc: 99.294% (49647/50000)\n",
      "Test Loss: 0.463 | Acc: 91.170% (9117/10000)\n",
      "\n",
      "Epoch: 90\n",
      "Train Loss: 0.016 | Acc: 99.434% (49717/50000)\n",
      "Test Loss: 0.471 | Acc: 91.400% (9140/10000)\n",
      "\n",
      "Epoch: 91\n",
      "Train Loss: 0.014 | Acc: 99.522% (49761/50000)\n",
      "Test Loss: 0.485 | Acc: 91.130% (9113/10000)\n",
      "\n",
      "Epoch: 92\n",
      "Train Loss: 0.015 | Acc: 99.482% (49741/50000)\n",
      "Test Loss: 0.463 | Acc: 91.250% (9125/10000)\n",
      "\n",
      "Epoch: 93\n",
      "Train Loss: 0.015 | Acc: 99.438% (49719/50000)\n",
      "Test Loss: 0.501 | Acc: 91.280% (9128/10000)\n",
      "\n",
      "Epoch: 94\n",
      "Train Loss: 0.013 | Acc: 99.522% (49761/50000)\n",
      "Test Loss: 0.507 | Acc: 91.180% (9118/10000)\n",
      "\n",
      "Epoch: 95\n",
      "Train Loss: 0.015 | Acc: 99.492% (49746/50000)\n",
      "Test Loss: 0.500 | Acc: 91.080% (9108/10000)\n",
      "\n",
      "Epoch: 96\n",
      "Train Loss: 0.014 | Acc: 99.478% (49739/50000)\n",
      "Test Loss: 0.510 | Acc: 91.060% (9106/10000)\n",
      "\n",
      "Epoch: 97\n",
      "Train Loss: 0.013 | Acc: 99.540% (49770/50000)\n",
      "Test Loss: 0.496 | Acc: 91.440% (9144/10000)\n",
      "\n",
      "Epoch: 98\n",
      "Train Loss: 0.014 | Acc: 99.516% (49758/50000)\n",
      "Test Loss: 0.473 | Acc: 91.430% (9143/10000)\n",
      "\n",
      "Epoch: 99\n",
      "Train Loss: 0.013 | Acc: 99.554% (49777/50000)\n",
      "Test Loss: 0.489 | Acc: 91.550% (9155/10000)\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+100):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
