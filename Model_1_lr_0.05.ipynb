{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff0c2e2-5551-449d-92d4-04d35e348472",
   "metadata": {},
   "source": [
    "Model 1, second run of the report.\n",
    "\n",
    "This is one of the first two runs mentioned in the report for model 1 with SGD optimizer with momentum=0.9, weight decay = 1e-4, learning rate=0.05. This gave a better results over the first run with learning rate = 0.1. It is a residual network consisting of 4 layers with 1,2,2,3 residual blocks. This run has provided us with the direction for tuning parameters of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7d0172-6e23-4bef-96aa-a1ef6289ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb88d0a-2202-43a8-92e8-735da2b63660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.linearh = nn.Linear(256*block.expansion, 512)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # out = self.layer5(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.linearh(out))\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18_reduced_param():\n",
    "    return ResNet(BasicBlock, [1, 2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f8c818-313e-4764-837b-e60181e8d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093866\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18_reduced_param()\n",
    "sum = 0\n",
    "for p in model.parameters():\n",
    "    sum += p.numel()\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09911b5c-db00-4dd5-ac76-eaadb943ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d6ea8c-b586-41c2-88bf-567cc97f95e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c134d38-16a3-4a11-8463-e7495e8bcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18_reduced_param()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb56658-df97-4346-8018-07d4e965491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05,\n",
    "                      momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efdc4a8-eb0a-49c2-96b7-c8e146fa45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('Train Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print('Test Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63921dc7-2e1d-4b48-b28b-027750c3f4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Loss: 1.694 | Acc: 36.956% (18478/50000)\n",
      "Test Loss: 1.600 | Acc: 43.930% (4393/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss: 1.226 | Acc: 56.058% (28029/50000)\n",
      "Test Loss: 1.178 | Acc: 58.700% (5870/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss: 0.954 | Acc: 66.432% (33216/50000)\n",
      "Test Loss: 1.036 | Acc: 66.180% (6618/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss: 0.788 | Acc: 72.810% (36405/50000)\n",
      "Test Loss: 0.722 | Acc: 74.480% (7448/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss: 0.675 | Acc: 76.636% (38318/50000)\n",
      "Test Loss: 0.716 | Acc: 76.030% (7603/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss: 0.598 | Acc: 79.454% (39727/50000)\n",
      "Test Loss: 0.648 | Acc: 78.420% (7842/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss: 0.542 | Acc: 81.304% (40652/50000)\n",
      "Test Loss: 0.595 | Acc: 79.380% (7938/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss: 0.499 | Acc: 82.856% (41428/50000)\n",
      "Test Loss: 0.527 | Acc: 82.400% (8240/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss: 0.471 | Acc: 83.804% (41902/50000)\n",
      "Test Loss: 0.469 | Acc: 84.140% (8414/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss: 0.437 | Acc: 84.978% (42489/50000)\n",
      "Test Loss: 0.454 | Acc: 84.770% (8477/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss: 0.414 | Acc: 85.766% (42883/50000)\n",
      "Test Loss: 0.526 | Acc: 82.940% (8294/10000)\n",
      "\n",
      "Epoch: 11\n",
      "Train Loss: 0.389 | Acc: 86.720% (43360/50000)\n",
      "Test Loss: 0.450 | Acc: 85.430% (8543/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 12\n",
      "Train Loss: 0.368 | Acc: 87.242% (43621/50000)\n",
      "Test Loss: 0.432 | Acc: 85.650% (8565/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 13\n",
      "Train Loss: 0.354 | Acc: 87.866% (43933/50000)\n",
      "Test Loss: 0.437 | Acc: 85.800% (8580/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      "Train Loss: 0.338 | Acc: 88.500% (44250/50000)\n",
      "Test Loss: 0.413 | Acc: 86.110% (8611/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 15\n",
      "Train Loss: 0.327 | Acc: 88.744% (44372/50000)\n",
      "Test Loss: 0.425 | Acc: 86.450% (8645/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 16\n",
      "Train Loss: 0.315 | Acc: 89.154% (44577/50000)\n",
      "Test Loss: 0.519 | Acc: 84.050% (8405/10000)\n",
      "\n",
      "Epoch: 17\n",
      "Train Loss: 0.309 | Acc: 89.166% (44583/50000)\n",
      "Test Loss: 0.405 | Acc: 86.240% (8624/10000)\n",
      "\n",
      "Epoch: 18\n",
      "Train Loss: 0.293 | Acc: 89.856% (44928/50000)\n",
      "Test Loss: 0.404 | Acc: 87.030% (8703/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      "Train Loss: 0.286 | Acc: 90.024% (45012/50000)\n",
      "Test Loss: 0.401 | Acc: 87.230% (8723/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      "Train Loss: 0.275 | Acc: 90.462% (45231/50000)\n",
      "Test Loss: 0.444 | Acc: 86.280% (8628/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Train Loss: 0.265 | Acc: 90.704% (45352/50000)\n",
      "Test Loss: 0.399 | Acc: 87.030% (8703/10000)\n",
      "\n",
      "Epoch: 22\n",
      "Train Loss: 0.256 | Acc: 91.126% (45563/50000)\n",
      "Test Loss: 0.484 | Acc: 84.770% (8477/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Train Loss: 0.249 | Acc: 91.392% (45696/50000)\n",
      "Test Loss: 0.355 | Acc: 88.310% (8831/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 24\n",
      "Train Loss: 0.245 | Acc: 91.638% (45819/50000)\n",
      "Test Loss: 0.392 | Acc: 87.600% (8760/10000)\n",
      "\n",
      "Epoch: 25\n",
      "Train Loss: 0.240 | Acc: 91.680% (45840/50000)\n",
      "Test Loss: 0.423 | Acc: 87.030% (8703/10000)\n",
      "\n",
      "Epoch: 26\n",
      "Train Loss: 0.238 | Acc: 91.684% (45842/50000)\n",
      "Test Loss: 0.364 | Acc: 88.110% (8811/10000)\n",
      "\n",
      "Epoch: 27\n",
      "Train Loss: 0.228 | Acc: 92.038% (46019/50000)\n",
      "Test Loss: 0.421 | Acc: 87.070% (8707/10000)\n",
      "\n",
      "Epoch: 28\n",
      "Train Loss: 0.227 | Acc: 92.060% (46030/50000)\n",
      "Test Loss: 0.408 | Acc: 86.990% (8699/10000)\n",
      "\n",
      "Epoch: 29\n",
      "Train Loss: 0.218 | Acc: 92.330% (46165/50000)\n",
      "Test Loss: 0.364 | Acc: 88.360% (8836/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 30\n",
      "Train Loss: 0.212 | Acc: 92.642% (46321/50000)\n",
      "Test Loss: 0.377 | Acc: 88.160% (8816/10000)\n",
      "\n",
      "Epoch: 31\n",
      "Train Loss: 0.208 | Acc: 92.696% (46348/50000)\n",
      "Test Loss: 0.387 | Acc: 87.540% (8754/10000)\n",
      "\n",
      "Epoch: 32\n",
      "Train Loss: 0.205 | Acc: 92.994% (46497/50000)\n",
      "Test Loss: 0.353 | Acc: 88.740% (8874/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 33\n",
      "Train Loss: 0.201 | Acc: 92.948% (46474/50000)\n",
      "Test Loss: 0.417 | Acc: 87.320% (8732/10000)\n",
      "\n",
      "Epoch: 34\n",
      "Train Loss: 0.200 | Acc: 93.102% (46551/50000)\n",
      "Test Loss: 0.387 | Acc: 88.030% (8803/10000)\n",
      "\n",
      "Epoch: 35\n",
      "Train Loss: 0.196 | Acc: 93.220% (46610/50000)\n",
      "Test Loss: 0.376 | Acc: 88.340% (8834/10000)\n",
      "\n",
      "Epoch: 36\n",
      "Train Loss: 0.185 | Acc: 93.484% (46742/50000)\n",
      "Test Loss: 0.430 | Acc: 87.200% (8720/10000)\n",
      "\n",
      "Epoch: 37\n",
      "Train Loss: 0.188 | Acc: 93.440% (46720/50000)\n",
      "Test Loss: 0.386 | Acc: 88.340% (8834/10000)\n",
      "\n",
      "Epoch: 38\n",
      "Train Loss: 0.180 | Acc: 93.556% (46778/50000)\n",
      "Test Loss: 0.354 | Acc: 88.830% (8883/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 39\n",
      "Train Loss: 0.182 | Acc: 93.622% (46811/50000)\n",
      "Test Loss: 0.409 | Acc: 87.600% (8760/10000)\n",
      "\n",
      "Epoch: 40\n",
      "Train Loss: 0.181 | Acc: 93.648% (46824/50000)\n",
      "Test Loss: 0.383 | Acc: 88.490% (8849/10000)\n",
      "\n",
      "Epoch: 41\n",
      "Train Loss: 0.173 | Acc: 93.948% (46974/50000)\n",
      "Test Loss: 0.344 | Acc: 89.730% (8973/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 42\n",
      "Train Loss: 0.172 | Acc: 93.996% (46998/50000)\n",
      "Test Loss: 0.389 | Acc: 88.580% (8858/10000)\n",
      "\n",
      "Epoch: 43\n",
      "Train Loss: 0.171 | Acc: 94.018% (47009/50000)\n",
      "Test Loss: 0.421 | Acc: 87.690% (8769/10000)\n",
      "\n",
      "Epoch: 44\n",
      "Train Loss: 0.167 | Acc: 94.198% (47099/50000)\n",
      "Test Loss: 0.343 | Acc: 89.260% (8926/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Train Loss: 0.168 | Acc: 94.102% (47051/50000)\n",
      "Test Loss: 0.411 | Acc: 87.900% (8790/10000)\n",
      "\n",
      "Epoch: 46\n",
      "Train Loss: 0.159 | Acc: 94.452% (47226/50000)\n",
      "Test Loss: 0.395 | Acc: 88.320% (8832/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Train Loss: 0.156 | Acc: 94.478% (47239/50000)\n",
      "Test Loss: 0.374 | Acc: 89.180% (8918/10000)\n",
      "\n",
      "Epoch: 48\n",
      "Train Loss: 0.160 | Acc: 94.402% (47201/50000)\n",
      "Test Loss: 0.384 | Acc: 88.310% (8831/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Train Loss: 0.154 | Acc: 94.570% (47285/50000)\n",
      "Test Loss: 0.387 | Acc: 88.950% (8895/10000)\n",
      "\n",
      "Epoch: 50\n",
      "Train Loss: 0.154 | Acc: 94.568% (47284/50000)\n",
      "Test Loss: 0.457 | Acc: 86.720% (8672/10000)\n",
      "\n",
      "Epoch: 51\n",
      "Train Loss: 0.153 | Acc: 94.680% (47340/50000)\n",
      "Test Loss: 0.341 | Acc: 89.650% (8965/10000)\n",
      "\n",
      "Epoch: 52\n",
      "Train Loss: 0.144 | Acc: 94.982% (47491/50000)\n",
      "Test Loss: 0.463 | Acc: 87.450% (8745/10000)\n",
      "\n",
      "Epoch: 53\n",
      "Train Loss: 0.145 | Acc: 94.978% (47489/50000)\n",
      "Test Loss: 0.457 | Acc: 86.940% (8694/10000)\n",
      "\n",
      "Epoch: 54\n",
      "Train Loss: 0.146 | Acc: 94.852% (47426/50000)\n",
      "Test Loss: 0.358 | Acc: 89.460% (8946/10000)\n",
      "\n",
      "Epoch: 55\n",
      "Train Loss: 0.143 | Acc: 94.988% (47494/50000)\n",
      "Test Loss: 0.345 | Acc: 89.450% (8945/10000)\n",
      "\n",
      "Epoch: 56\n",
      "Train Loss: 0.140 | Acc: 95.092% (47546/50000)\n",
      "Test Loss: 0.358 | Acc: 89.480% (8948/10000)\n",
      "\n",
      "Epoch: 57\n",
      "Train Loss: 0.139 | Acc: 95.110% (47555/50000)\n",
      "Test Loss: 0.340 | Acc: 89.670% (8967/10000)\n",
      "\n",
      "Epoch: 58\n",
      "Train Loss: 0.134 | Acc: 95.350% (47675/50000)\n",
      "Test Loss: 0.381 | Acc: 89.240% (8924/10000)\n",
      "\n",
      "Epoch: 59\n",
      "Train Loss: 0.138 | Acc: 95.096% (47548/50000)\n",
      "Test Loss: 0.363 | Acc: 89.240% (8924/10000)\n",
      "\n",
      "Epoch: 60\n",
      "Train Loss: 0.131 | Acc: 95.400% (47700/50000)\n",
      "Test Loss: 0.373 | Acc: 89.360% (8936/10000)\n",
      "\n",
      "Epoch: 61\n",
      "Train Loss: 0.131 | Acc: 95.406% (47703/50000)\n",
      "Test Loss: 0.369 | Acc: 89.750% (8975/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 62\n",
      "Train Loss: 0.129 | Acc: 95.438% (47719/50000)\n",
      "Test Loss: 0.357 | Acc: 89.180% (8918/10000)\n",
      "\n",
      "Epoch: 63\n",
      "Train Loss: 0.128 | Acc: 95.530% (47765/50000)\n",
      "Test Loss: 0.364 | Acc: 90.020% (9002/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 64\n",
      "Train Loss: 0.127 | Acc: 95.394% (47697/50000)\n",
      "Test Loss: 0.349 | Acc: 90.220% (9022/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 65\n",
      "Train Loss: 0.120 | Acc: 95.808% (47904/50000)\n",
      "Test Loss: 0.366 | Acc: 89.890% (8989/10000)\n",
      "\n",
      "Epoch: 66\n",
      "Train Loss: 0.121 | Acc: 95.690% (47845/50000)\n",
      "Test Loss: 0.359 | Acc: 89.960% (8996/10000)\n",
      "\n",
      "Epoch: 67\n",
      "Train Loss: 0.117 | Acc: 96.042% (48021/50000)\n",
      "Test Loss: 0.352 | Acc: 90.110% (9011/10000)\n",
      "\n",
      "Epoch: 68\n",
      "Train Loss: 0.119 | Acc: 95.842% (47921/50000)\n",
      "Test Loss: 0.405 | Acc: 89.110% (8911/10000)\n",
      "\n",
      "Epoch: 69\n",
      "Train Loss: 0.116 | Acc: 95.946% (47973/50000)\n",
      "Test Loss: 0.368 | Acc: 89.730% (8973/10000)\n",
      "\n",
      "Epoch: 70\n",
      "Train Loss: 0.113 | Acc: 96.036% (48018/50000)\n",
      "Test Loss: 0.371 | Acc: 89.640% (8964/10000)\n",
      "\n",
      "Epoch: 71\n",
      "Train Loss: 0.108 | Acc: 96.170% (48085/50000)\n",
      "Test Loss: 0.412 | Acc: 89.450% (8945/10000)\n",
      "\n",
      "Epoch: 72\n",
      "Train Loss: 0.116 | Acc: 95.878% (47939/50000)\n",
      "Test Loss: 0.370 | Acc: 89.820% (8982/10000)\n",
      "\n",
      "Epoch: 73\n",
      "Train Loss: 0.110 | Acc: 96.128% (48064/50000)\n",
      "Test Loss: 0.354 | Acc: 90.500% (9050/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 74\n",
      "Train Loss: 0.110 | Acc: 96.152% (48076/50000)\n",
      "Test Loss: 0.330 | Acc: 90.680% (9068/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 75\n",
      "Train Loss: 0.105 | Acc: 96.226% (48113/50000)\n",
      "Test Loss: 0.363 | Acc: 89.980% (8998/10000)\n",
      "\n",
      "Epoch: 76\n",
      "Train Loss: 0.107 | Acc: 96.276% (48138/50000)\n",
      "Test Loss: 0.376 | Acc: 89.690% (8969/10000)\n",
      "\n",
      "Epoch: 77\n",
      "Train Loss: 0.104 | Acc: 96.300% (48150/50000)\n",
      "Test Loss: 0.386 | Acc: 89.440% (8944/10000)\n",
      "\n",
      "Epoch: 78\n",
      "Train Loss: 0.101 | Acc: 96.480% (48240/50000)\n",
      "Test Loss: 0.409 | Acc: 89.100% (8910/10000)\n",
      "\n",
      "Epoch: 79\n",
      "Train Loss: 0.098 | Acc: 96.678% (48339/50000)\n",
      "Test Loss: 0.345 | Acc: 90.440% (9044/10000)\n",
      "\n",
      "Epoch: 80\n",
      "Train Loss: 0.098 | Acc: 96.590% (48295/50000)\n",
      "Test Loss: 0.339 | Acc: 90.500% (9050/10000)\n",
      "\n",
      "Epoch: 81\n",
      "Train Loss: 0.093 | Acc: 96.738% (48369/50000)\n",
      "Test Loss: 0.348 | Acc: 90.630% (9063/10000)\n",
      "\n",
      "Epoch: 82\n",
      "Train Loss: 0.095 | Acc: 96.698% (48349/50000)\n",
      "Test Loss: 0.319 | Acc: 91.130% (9113/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 83\n",
      "Train Loss: 0.091 | Acc: 96.858% (48429/50000)\n",
      "Test Loss: 0.411 | Acc: 89.220% (8922/10000)\n",
      "\n",
      "Epoch: 84\n",
      "Train Loss: 0.092 | Acc: 96.754% (48377/50000)\n",
      "Test Loss: 0.370 | Acc: 90.070% (9007/10000)\n",
      "\n",
      "Epoch: 85\n",
      "Train Loss: 0.089 | Acc: 96.916% (48458/50000)\n",
      "Test Loss: 0.377 | Acc: 89.830% (8983/10000)\n",
      "\n",
      "Epoch: 86\n",
      "Train Loss: 0.092 | Acc: 96.740% (48370/50000)\n",
      "Test Loss: 0.339 | Acc: 90.990% (9099/10000)\n",
      "\n",
      "Epoch: 87\n",
      "Train Loss: 0.088 | Acc: 96.944% (48472/50000)\n",
      "Test Loss: 0.340 | Acc: 90.950% (9095/10000)\n",
      "\n",
      "Epoch: 88\n",
      "Train Loss: 0.090 | Acc: 96.836% (48418/50000)\n",
      "Test Loss: 0.340 | Acc: 90.410% (9041/10000)\n",
      "\n",
      "Epoch: 89\n",
      "Train Loss: 0.083 | Acc: 97.096% (48548/50000)\n",
      "Test Loss: 0.344 | Acc: 90.700% (9070/10000)\n",
      "\n",
      "Epoch: 90\n",
      "Train Loss: 0.085 | Acc: 97.088% (48544/50000)\n",
      "Test Loss: 0.307 | Acc: 91.450% (9145/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 91\n",
      "Train Loss: 0.080 | Acc: 97.184% (48592/50000)\n",
      "Test Loss: 0.351 | Acc: 90.760% (9076/10000)\n",
      "\n",
      "Epoch: 92\n",
      "Train Loss: 0.078 | Acc: 97.250% (48625/50000)\n",
      "Test Loss: 0.373 | Acc: 90.060% (9006/10000)\n",
      "\n",
      "Epoch: 93\n",
      "Train Loss: 0.074 | Acc: 97.442% (48721/50000)\n",
      "Test Loss: 0.313 | Acc: 91.310% (9131/10000)\n",
      "\n",
      "Epoch: 94\n",
      "Train Loss: 0.078 | Acc: 97.236% (48618/50000)\n",
      "Test Loss: 0.308 | Acc: 91.270% (9127/10000)\n",
      "\n",
      "Epoch: 95\n",
      "Train Loss: 0.071 | Acc: 97.514% (48757/50000)\n",
      "Test Loss: 0.411 | Acc: 89.700% (8970/10000)\n",
      "\n",
      "Epoch: 96\n",
      "Train Loss: 0.068 | Acc: 97.622% (48811/50000)\n",
      "Test Loss: 0.341 | Acc: 91.190% (9119/10000)\n",
      "\n",
      "Epoch: 97\n",
      "Train Loss: 0.069 | Acc: 97.650% (48825/50000)\n",
      "Test Loss: 0.341 | Acc: 91.330% (9133/10000)\n",
      "\n",
      "Epoch: 98\n",
      "Train Loss: 0.070 | Acc: 97.504% (48752/50000)\n",
      "Test Loss: 0.341 | Acc: 91.170% (9117/10000)\n",
      "\n",
      "Epoch: 99\n",
      "Train Loss: 0.067 | Acc: 97.668% (48834/50000)\n",
      "Test Loss: 0.325 | Acc: 91.760% (9176/10000)\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+100):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3199c83-0c76-4ea9-9092-98146c265720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
