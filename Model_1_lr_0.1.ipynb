{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d360b90a-bee2-49b8-986f-68cb450331a2",
   "metadata": {},
   "source": [
    "Model 1, 1st run with defined parameters\n",
    "\n",
    "In this experiment the we started with a learning rate of 0.1, weight decay as 0.0001, optimizer as SGD with a residual network which consists of 4 layers with 1,2,2,3 residual blocks respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7d0172-6e23-4bef-96aa-a1ef6289ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "#from models import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb88d0a-2202-43a8-92e8-735da2b63660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.linearh = nn.Linear(256*block.expansion, 512)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # out = self.layer5(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.linearh(out))\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18_reduced_param():\n",
    "    return ResNet(BasicBlock, [1, 2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f8c818-313e-4764-837b-e60181e8d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093866\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18_reduced_param()\n",
    "sum = 0\n",
    "for p in model.parameters():\n",
    "    sum += p.numel()\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09911b5c-db00-4dd5-ac76-eaadb943ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d6ea8c-b586-41c2-88bf-567cc97f95e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c134d38-16a3-4a11-8463-e7495e8bcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18_reduced_param()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb56658-df97-4346-8018-07d4e965491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0efdc4a8-eb0a-49c2-96b7-c8e146fa45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('Train Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print('Test Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63921dc7-2e1d-4b48-b28b-027750c3f4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Loss: 1.903 | Acc: 26.506% (13253/50000)\n",
      "Test Loss: 1.706 | Acc: 36.100% (3610/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss: 1.416 | Acc: 48.008% (24004/50000)\n",
      "Test Loss: 1.241 | Acc: 55.900% (5590/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss: 1.063 | Acc: 61.928% (30964/50000)\n",
      "Test Loss: 1.052 | Acc: 62.980% (6298/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss: 0.856 | Acc: 69.934% (34967/50000)\n",
      "Test Loss: 0.845 | Acc: 71.250% (7125/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss: 0.730 | Acc: 74.918% (37459/50000)\n",
      "Test Loss: 0.747 | Acc: 74.450% (7445/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss: 0.644 | Acc: 77.870% (38935/50000)\n",
      "Test Loss: 0.708 | Acc: 76.750% (7675/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss: 0.594 | Acc: 79.720% (39860/50000)\n",
      "Test Loss: 0.651 | Acc: 78.330% (7833/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss: 0.556 | Acc: 81.032% (40516/50000)\n",
      "Test Loss: 0.594 | Acc: 79.570% (7957/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss: 0.513 | Acc: 82.498% (41249/50000)\n",
      "Test Loss: 0.623 | Acc: 79.530% (7953/10000)\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss: 0.486 | Acc: 83.422% (41711/50000)\n",
      "Test Loss: 0.546 | Acc: 82.300% (8230/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss: 0.464 | Acc: 84.042% (42021/50000)\n",
      "Test Loss: 0.571 | Acc: 80.700% (8070/10000)\n",
      "\n",
      "Epoch: 11\n",
      "Train Loss: 0.441 | Acc: 84.830% (42415/50000)\n",
      "Test Loss: 0.529 | Acc: 82.040% (8204/10000)\n",
      "\n",
      "Epoch: 12\n",
      "Train Loss: 0.433 | Acc: 85.162% (42581/50000)\n",
      "Test Loss: 0.537 | Acc: 82.460% (8246/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 13\n",
      "Train Loss: 0.411 | Acc: 86.052% (43026/50000)\n",
      "Test Loss: 0.519 | Acc: 82.880% (8288/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      "Train Loss: 0.399 | Acc: 86.318% (43159/50000)\n",
      "Test Loss: 0.512 | Acc: 83.030% (8303/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 15\n",
      "Train Loss: 0.388 | Acc: 86.498% (43249/50000)\n",
      "Test Loss: 0.491 | Acc: 83.960% (8396/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 16\n",
      "Train Loss: 0.377 | Acc: 87.094% (43547/50000)\n",
      "Test Loss: 0.469 | Acc: 84.380% (8438/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 17\n",
      "Train Loss: 0.369 | Acc: 87.336% (43668/50000)\n",
      "Test Loss: 0.507 | Acc: 83.530% (8353/10000)\n",
      "\n",
      "Epoch: 18\n",
      "Train Loss: 0.358 | Acc: 87.638% (43819/50000)\n",
      "Test Loss: 0.447 | Acc: 85.560% (8556/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      "Train Loss: 0.351 | Acc: 87.926% (43963/50000)\n",
      "Test Loss: 0.459 | Acc: 84.740% (8474/10000)\n",
      "\n",
      "Epoch: 20\n",
      "Train Loss: 0.335 | Acc: 88.412% (44206/50000)\n",
      "Test Loss: 0.503 | Acc: 83.940% (8394/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Train Loss: 0.336 | Acc: 88.428% (44214/50000)\n",
      "Test Loss: 0.427 | Acc: 85.760% (8576/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 22\n",
      "Train Loss: 0.327 | Acc: 88.730% (44365/50000)\n",
      "Test Loss: 0.437 | Acc: 85.710% (8571/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Train Loss: 0.320 | Acc: 89.068% (44534/50000)\n",
      "Test Loss: 0.436 | Acc: 86.100% (8610/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 24\n",
      "Train Loss: 0.312 | Acc: 89.238% (44619/50000)\n",
      "Test Loss: 0.501 | Acc: 84.600% (8460/10000)\n",
      "\n",
      "Epoch: 25\n",
      "Train Loss: 0.308 | Acc: 89.356% (44678/50000)\n",
      "Test Loss: 0.451 | Acc: 85.620% (8562/10000)\n",
      "\n",
      "Epoch: 26\n",
      "Train Loss: 0.308 | Acc: 89.426% (44713/50000)\n",
      "Test Loss: 0.384 | Acc: 87.170% (8717/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 27\n",
      "Train Loss: 0.302 | Acc: 89.450% (44725/50000)\n",
      "Test Loss: 0.397 | Acc: 87.170% (8717/10000)\n",
      "\n",
      "Epoch: 28\n",
      "Train Loss: 0.296 | Acc: 89.732% (44866/50000)\n",
      "Test Loss: 0.413 | Acc: 86.190% (8619/10000)\n",
      "\n",
      "Epoch: 29\n",
      "Train Loss: 0.289 | Acc: 90.006% (45003/50000)\n",
      "Test Loss: 0.455 | Acc: 85.890% (8589/10000)\n",
      "\n",
      "Epoch: 30\n",
      "Train Loss: 0.291 | Acc: 89.948% (44974/50000)\n",
      "Test Loss: 0.454 | Acc: 85.660% (8566/10000)\n",
      "\n",
      "Epoch: 31\n",
      "Train Loss: 0.283 | Acc: 90.154% (45077/50000)\n",
      "Test Loss: 0.566 | Acc: 83.010% (8301/10000)\n",
      "\n",
      "Epoch: 32\n",
      "Train Loss: 0.277 | Acc: 90.522% (45261/50000)\n",
      "Test Loss: 0.434 | Acc: 86.140% (8614/10000)\n",
      "\n",
      "Epoch: 33\n",
      "Train Loss: 0.280 | Acc: 90.278% (45139/50000)\n",
      "Test Loss: 0.378 | Acc: 87.890% (8789/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 34\n",
      "Train Loss: 0.271 | Acc: 90.684% (45342/50000)\n",
      "Test Loss: 0.415 | Acc: 86.400% (8640/10000)\n",
      "\n",
      "Epoch: 35\n",
      "Train Loss: 0.264 | Acc: 90.952% (45476/50000)\n",
      "Test Loss: 0.423 | Acc: 86.530% (8653/10000)\n",
      "\n",
      "Epoch: 36\n",
      "Train Loss: 0.266 | Acc: 90.758% (45379/50000)\n",
      "Test Loss: 0.381 | Acc: 87.650% (8765/10000)\n",
      "\n",
      "Epoch: 37\n",
      "Train Loss: 0.264 | Acc: 90.896% (45448/50000)\n",
      "Test Loss: 0.416 | Acc: 86.850% (8685/10000)\n",
      "\n",
      "Epoch: 38\n",
      "Train Loss: 0.259 | Acc: 90.936% (45468/50000)\n",
      "Test Loss: 0.375 | Acc: 88.070% (8807/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 39\n",
      "Train Loss: 0.261 | Acc: 91.026% (45513/50000)\n",
      "Test Loss: 0.393 | Acc: 87.590% (8759/10000)\n",
      "\n",
      "Epoch: 40\n",
      "Train Loss: 0.256 | Acc: 91.086% (45543/50000)\n",
      "Test Loss: 0.420 | Acc: 86.660% (8666/10000)\n",
      "\n",
      "Epoch: 41\n",
      "Train Loss: 0.255 | Acc: 91.100% (45550/50000)\n",
      "Test Loss: 0.358 | Acc: 88.620% (8862/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 42\n",
      "Train Loss: 0.244 | Acc: 91.456% (45728/50000)\n",
      "Test Loss: 0.402 | Acc: 87.360% (8736/10000)\n",
      "\n",
      "Epoch: 43\n",
      "Train Loss: 0.249 | Acc: 91.450% (45725/50000)\n",
      "Test Loss: 0.360 | Acc: 87.760% (8776/10000)\n",
      "\n",
      "Epoch: 44\n",
      "Train Loss: 0.243 | Acc: 91.554% (45777/50000)\n",
      "Test Loss: 0.398 | Acc: 86.990% (8699/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Train Loss: 0.236 | Acc: 91.766% (45883/50000)\n",
      "Test Loss: 0.416 | Acc: 86.910% (8691/10000)\n",
      "\n",
      "Epoch: 46\n",
      "Train Loss: 0.235 | Acc: 91.816% (45908/50000)\n",
      "Test Loss: 0.395 | Acc: 87.680% (8768/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Train Loss: 0.236 | Acc: 91.786% (45893/50000)\n",
      "Test Loss: 0.352 | Acc: 88.660% (8866/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 48\n",
      "Train Loss: 0.231 | Acc: 92.098% (46049/50000)\n",
      "Test Loss: 0.360 | Acc: 88.570% (8857/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Train Loss: 0.227 | Acc: 92.128% (46064/50000)\n",
      "Test Loss: 0.360 | Acc: 88.640% (8864/10000)\n",
      "\n",
      "Epoch: 50\n",
      "Train Loss: 0.230 | Acc: 92.178% (46089/50000)\n",
      "Test Loss: 0.392 | Acc: 87.470% (8747/10000)\n",
      "\n",
      "Epoch: 51\n",
      "Train Loss: 0.225 | Acc: 92.126% (46063/50000)\n",
      "Test Loss: 0.415 | Acc: 87.590% (8759/10000)\n",
      "\n",
      "Epoch: 52\n",
      "Train Loss: 0.222 | Acc: 92.264% (46132/50000)\n",
      "Test Loss: 0.422 | Acc: 86.750% (8675/10000)\n",
      "\n",
      "Epoch: 53\n",
      "Train Loss: 0.222 | Acc: 92.182% (46091/50000)\n",
      "Test Loss: 0.370 | Acc: 88.690% (8869/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 54\n",
      "Train Loss: 0.216 | Acc: 92.470% (46235/50000)\n",
      "Test Loss: 0.336 | Acc: 89.200% (8920/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 55\n",
      "Train Loss: 0.220 | Acc: 92.402% (46201/50000)\n",
      "Test Loss: 0.379 | Acc: 87.760% (8776/10000)\n",
      "\n",
      "Epoch: 56\n",
      "Train Loss: 0.210 | Acc: 92.816% (46408/50000)\n",
      "Test Loss: 0.379 | Acc: 87.900% (8790/10000)\n",
      "\n",
      "Epoch: 57\n",
      "Train Loss: 0.215 | Acc: 92.500% (46250/50000)\n",
      "Test Loss: 0.373 | Acc: 88.500% (8850/10000)\n",
      "\n",
      "Epoch: 58\n",
      "Train Loss: 0.208 | Acc: 92.778% (46389/50000)\n",
      "Test Loss: 0.375 | Acc: 88.020% (8802/10000)\n",
      "\n",
      "Epoch: 59\n",
      "Train Loss: 0.213 | Acc: 92.544% (46272/50000)\n",
      "Test Loss: 0.384 | Acc: 87.940% (8794/10000)\n",
      "\n",
      "Epoch: 60\n",
      "Train Loss: 0.208 | Acc: 92.664% (46332/50000)\n",
      "Test Loss: 0.376 | Acc: 88.280% (8828/10000)\n",
      "\n",
      "Epoch: 61\n",
      "Train Loss: 0.205 | Acc: 92.894% (46447/50000)\n",
      "Test Loss: 0.349 | Acc: 88.830% (8883/10000)\n",
      "\n",
      "Epoch: 62\n",
      "Train Loss: 0.206 | Acc: 92.674% (46337/50000)\n",
      "Test Loss: 0.365 | Acc: 88.680% (8868/10000)\n",
      "\n",
      "Epoch: 63\n",
      "Train Loss: 0.198 | Acc: 93.074% (46537/50000)\n",
      "Test Loss: 0.354 | Acc: 89.210% (8921/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 64\n",
      "Train Loss: 0.199 | Acc: 93.070% (46535/50000)\n",
      "Test Loss: 0.330 | Acc: 89.210% (8921/10000)\n",
      "\n",
      "Epoch: 65\n",
      "Train Loss: 0.197 | Acc: 93.118% (46559/50000)\n",
      "Test Loss: 0.503 | Acc: 84.710% (8471/10000)\n",
      "\n",
      "Epoch: 66\n",
      "Train Loss: 0.193 | Acc: 93.334% (46667/50000)\n",
      "Test Loss: 0.363 | Acc: 88.770% (8877/10000)\n",
      "\n",
      "Epoch: 67\n",
      "Train Loss: 0.194 | Acc: 93.338% (46669/50000)\n",
      "Test Loss: 0.433 | Acc: 86.680% (8668/10000)\n",
      "\n",
      "Epoch: 68\n",
      "Train Loss: 0.193 | Acc: 93.278% (46639/50000)\n",
      "Test Loss: 0.364 | Acc: 89.220% (8922/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 69\n",
      "Train Loss: 0.189 | Acc: 93.558% (46779/50000)\n",
      "Test Loss: 0.354 | Acc: 88.740% (8874/10000)\n",
      "\n",
      "Epoch: 70\n",
      "Train Loss: 0.182 | Acc: 93.658% (46829/50000)\n",
      "Test Loss: 0.365 | Acc: 89.410% (8941/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 71\n",
      "Train Loss: 0.189 | Acc: 93.404% (46702/50000)\n",
      "Test Loss: 0.370 | Acc: 88.630% (8863/10000)\n",
      "\n",
      "Epoch: 72\n",
      "Train Loss: 0.179 | Acc: 93.828% (46914/50000)\n",
      "Test Loss: 0.340 | Acc: 89.720% (8972/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 73\n",
      "Train Loss: 0.178 | Acc: 93.776% (46888/50000)\n",
      "Test Loss: 0.344 | Acc: 89.320% (8932/10000)\n",
      "\n",
      "Epoch: 74\n",
      "Train Loss: 0.182 | Acc: 93.590% (46795/50000)\n",
      "Test Loss: 0.385 | Acc: 88.670% (8867/10000)\n",
      "\n",
      "Epoch: 75\n",
      "Train Loss: 0.177 | Acc: 93.856% (46928/50000)\n",
      "Test Loss: 0.359 | Acc: 89.090% (8909/10000)\n",
      "\n",
      "Epoch: 76\n",
      "Train Loss: 0.169 | Acc: 94.088% (47044/50000)\n",
      "Test Loss: 0.371 | Acc: 88.970% (8897/10000)\n",
      "\n",
      "Epoch: 77\n",
      "Train Loss: 0.171 | Acc: 94.000% (47000/50000)\n",
      "Test Loss: 0.396 | Acc: 88.300% (8830/10000)\n",
      "\n",
      "Epoch: 78\n",
      "Train Loss: 0.169 | Acc: 94.076% (47038/50000)\n",
      "Test Loss: 0.354 | Acc: 89.250% (8925/10000)\n",
      "\n",
      "Epoch: 79\n",
      "Train Loss: 0.168 | Acc: 94.124% (47062/50000)\n",
      "Test Loss: 0.352 | Acc: 88.930% (8893/10000)\n",
      "\n",
      "Epoch: 80\n",
      "Train Loss: 0.164 | Acc: 94.228% (47114/50000)\n",
      "Test Loss: 0.383 | Acc: 88.820% (8882/10000)\n",
      "\n",
      "Epoch: 81\n",
      "Train Loss: 0.163 | Acc: 94.252% (47126/50000)\n",
      "Test Loss: 0.336 | Acc: 90.060% (9006/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 82\n",
      "Train Loss: 0.168 | Acc: 94.228% (47114/50000)\n",
      "Test Loss: 0.334 | Acc: 89.930% (8993/10000)\n",
      "\n",
      "Epoch: 83\n",
      "Train Loss: 0.157 | Acc: 94.414% (47207/50000)\n",
      "Test Loss: 0.333 | Acc: 89.890% (8989/10000)\n",
      "\n",
      "Epoch: 84\n",
      "Train Loss: 0.162 | Acc: 94.212% (47106/50000)\n",
      "Test Loss: 0.409 | Acc: 87.770% (8777/10000)\n",
      "\n",
      "Epoch: 85\n",
      "Train Loss: 0.151 | Acc: 94.820% (47410/50000)\n",
      "Test Loss: 0.403 | Acc: 88.410% (8841/10000)\n",
      "\n",
      "Epoch: 86\n",
      "Train Loss: 0.155 | Acc: 94.598% (47299/50000)\n",
      "Test Loss: 0.339 | Acc: 89.160% (8916/10000)\n",
      "\n",
      "Epoch: 87\n",
      "Train Loss: 0.147 | Acc: 94.876% (47438/50000)\n",
      "Test Loss: 0.466 | Acc: 87.280% (8728/10000)\n",
      "\n",
      "Epoch: 88\n",
      "Train Loss: 0.153 | Acc: 94.724% (47362/50000)\n",
      "Test Loss: 0.290 | Acc: 90.890% (9089/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 89\n",
      "Train Loss: 0.146 | Acc: 94.918% (47459/50000)\n",
      "Test Loss: 0.316 | Acc: 90.460% (9046/10000)\n",
      "\n",
      "Epoch: 90\n",
      "Train Loss: 0.140 | Acc: 95.088% (47544/50000)\n",
      "Test Loss: 0.363 | Acc: 88.990% (8899/10000)\n",
      "\n",
      "Epoch: 91\n",
      "Train Loss: 0.140 | Acc: 95.092% (47546/50000)\n",
      "Test Loss: 0.360 | Acc: 89.320% (8932/10000)\n",
      "\n",
      "Epoch: 92\n",
      "Train Loss: 0.140 | Acc: 95.114% (47557/50000)\n",
      "Test Loss: 0.350 | Acc: 89.820% (8982/10000)\n",
      "\n",
      "Epoch: 93\n",
      "Train Loss: 0.139 | Acc: 95.108% (47554/50000)\n",
      "Test Loss: 0.388 | Acc: 88.710% (8871/10000)\n",
      "\n",
      "Epoch: 94\n",
      "Train Loss: 0.133 | Acc: 95.422% (47711/50000)\n",
      "Test Loss: 0.329 | Acc: 89.930% (8993/10000)\n",
      "\n",
      "Epoch: 95\n",
      "Train Loss: 0.136 | Acc: 95.134% (47567/50000)\n",
      "Test Loss: 0.321 | Acc: 90.230% (9023/10000)\n",
      "\n",
      "Epoch: 96\n",
      "Train Loss: 0.126 | Acc: 95.628% (47814/50000)\n",
      "Test Loss: 0.344 | Acc: 89.920% (8992/10000)\n",
      "\n",
      "Epoch: 97\n",
      "Train Loss: 0.133 | Acc: 95.248% (47624/50000)\n",
      "Test Loss: 0.322 | Acc: 90.300% (9030/10000)\n",
      "\n",
      "Epoch: 98\n",
      "Train Loss: 0.131 | Acc: 95.398% (47699/50000)\n",
      "Test Loss: 0.344 | Acc: 89.870% (8987/10000)\n",
      "\n",
      "Epoch: 99\n",
      "Train Loss: 0.124 | Acc: 95.622% (47811/50000)\n",
      "Test Loss: 0.344 | Acc: 89.540% (8954/10000)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+100):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3199c83-0c76-4ea9-9092-98146c265720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
